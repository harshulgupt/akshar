"""
Script to train the Brahmi to Devanagari transliteration model
"""

import os
import sys
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Add the src directory to the path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.transliteration_model import BrahmiToDevanagariTransliterator, create_parallel_corpus, load_parallel_corpus

def prepare_synthetic_corpus(output_file):
    """
    Prepare a synthetic parallel corpus of Brahmi and Devanagari character sequences.
    
    Args:
        output_file (str): Path to output file
        
    Returns:
        pd.DataFrame: Parallel corpus
    """
    # Define Brahmi characters and their Devanagari equivalents
    brahmi_chars = [
        'ð‘€…', 'ð‘€†', 'ð‘€‡', 'ð‘€ˆ', 'ð‘€‰', 'ð‘€Š', 'ð‘€‹', 'ð‘€Œ', 'ð‘€', 'ð‘€Ž',
        'ð‘€', 'ð‘€', 'ð‘€‘', 'ð‘€’', 'ð‘€“', 'ð‘€”', 'ð‘€•', 'ð‘€–', 'ð‘€—', 'ð‘€˜',
        'ð‘€™', 'ð‘€š', 'ð‘€›', 'ð‘€œ', 'ð‘€', 'ð‘€ž', 'ð‘€Ÿ', 'ð‘€ ', 'ð‘€¡', 'ð‘€¢',
        'ð‘€£', 'ð‘€¤', 'ð‘€¥', 'ð‘€¦', 'ð‘€§', 'ð‘€¨', 'ð‘€©', 'ð‘€ª', 'ð‘€«', 'ð‘€¬',
        'ð‘€­', 'ð‘€®', 'ð‘€¯', 'ð‘€°', 'ð‘€±', 'ð‘€²', 'ð‘€³', 'ð‘€´', 'ð‘€µ', 'ð‘€¶',
        'ð‘€·', 'ð‘€¸', 'ð‘€¹', 'ð‘€º', 'ð‘€»', 'ð‘€¼', 'ð‘€½', 'ð‘€¾', 'ð‘€¿', 'ð‘€',
        'ð‘', 'ð‘‚', 'ð‘ƒ', 'ð‘„', 'ð‘…', 'ð‘†', 'ð‘‡', 'ð‘ˆ', 'ð‘‰', 'ð‘Š',
        'ð‘‹', 'ð‘Œ', 'ð‘', 'ð‘Ž', 'ð‘', 'ð‘', 'ð‘‘', 'ð‘’', 'ð‘“', 'ð‘”',
        'ð‘•', 'ð‘–', 'ð‘—', 'ð‘˜', 'ð‘™', 'ð‘š', 'ð‘›', 'ð‘œ', 'ð‘', 'ð‘ž',
        'ð‘Ÿ', 'ð‘ ', 'ð‘¡', 'ð‘¢', 'ð‘£', 'ð‘¤', 'ð‘¥', 'ð‘¦', 'ð‘§', 'ð‘¨'
    ]
    
    devanagari_chars = [
        'à¤…', 'à¤†', 'à¤‡', 'à¤ˆ', 'à¤‰', 'à¤Š', 'à¤‹', 'à¥ ', 'à¤Œ', 'à¥¡',
        'à¤', 'à¤', 'à¤“', 'à¤”', 'à¤•', 'à¤–', 'à¤—', 'à¤˜', 'à¤™', 'à¤š',
        'à¤›', 'à¤œ', 'à¤', 'à¤ž', 'à¤Ÿ', 'à¤ ', 'à¤¡', 'à¤¢', 'à¤£', 'à¤¤',
        'à¤¥', 'à¤¦', 'à¤§', 'à¤¨', 'à¤ª', 'à¤«', 'à¤¬', 'à¤­', 'à¤®', 'à¤¯',
        'à¤°', 'à¤²', 'à¤µ', 'à¤¶', 'à¤·', 'à¤¸', 'à¤¹', 'à¤³', 'à¤•à¥à¤·', 'à¤œà¥à¤ž',
        'à¥¦', 'à¤¾', 'à¤¿', 'à¥€', 'à¥', 'à¥‚', 'à¥ƒ', 'à¥„', 'à¥¢', 'à¥£',
        'à¥‡', 'à¥ˆ', 'à¥‹', 'à¥Œ', 'à¥', 'à¥', 'à¥¤', 'à¥¥', 'à¥§', 'à¥¨',
        'à¥©', 'à¥ª', 'à¥«', 'à¥¬', 'à¥­', 'à¥®', 'à¥¯', 'à¥¦', 'à¥°', 'à¥°',
        'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°',
        'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°', 'à¥°'
    ]
    
    # Create synthetic corpus
    corpus = create_parallel_corpus(
        brahmi_chars, 
        devanagari_chars, 
        output_file,
        num_samples=5000,  # Reduced from 10000
        max_length=8       # Reduced from 10
    )
    
    print(f"Created synthetic corpus with {len(corpus)} samples")
    print("Sample entries:")
    print(corpus.head())
    
    return corpus

def prepare_academic_corpus(output_file):
    """
    Prepare an academic parallel corpus of Brahmi and Devanagari character sequences.
    
    Args:
        output_file (str): Path to output file
        
    Returns:
        pd.DataFrame: Parallel corpus
    """
    # Define academic examples
    brahmi_texts = [
        'ð‘€“ð‘€¸ð‘€¯ð‘€º',
        'ð‘€…ð‘€²ð‘„ð‘€“',
        'ð‘€¥ð‘€¼ð‘€¤ð‘†ð‘€¥',
        'ð‘€¤ð‘€«ð‘†ð‘€«',
        'ð‘€²ð‘€ð‘€–',
        'ð‘€§ð‘†ð‘€­ð‘€¸ð‘€³ð‘†ð‘€«ð‘€º',
        'ð‘€¤ð‘‚ð‘€¯ð‘€¦ð‘€¸ð‘€•ð‘€­ð‘€»',
        'ð‘€®ð‘€ºð‘€§ð‘€º',
        'ð‘€…ð‘€“ð‘†ð‘€±ð‘€­',
        'ð‘€¯ð‘€­ð‘†ð‘€¡ð‘€«ð‘€¸ð‘€®ð‘€¸'
    ]
    
    devanagari_texts = [
        'à¤•à¤¾à¤µà¥€',
        'à¤…à¤¶à¥‹à¤•',
        'à¤¬à¥à¤¦à¥à¤§',
        'à¤§à¤®à¥à¤®',
        'à¤¸à¤‚à¤˜',
        'à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤¿',
        'à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€',
        'à¤²à¤¿à¤ªà¤¿',
        'à¤…à¤•à¥à¤·à¤°',
        'à¤µà¤°à¥à¤£à¤®à¤¾à¤²à¤¾'
    ]
    
    # Create DataFrame
    corpus = pd.DataFrame({
        'brahmi': brahmi_texts,
        'devanagari': devanagari_texts
    })
    
    # Save to file
    corpus.to_csv(output_file, index=False)
    
    print(f"Created academic corpus with {len(corpus)} samples")
    print("Sample entries:")
    print(corpus.head())
    
    return corpus

def merge_corpora(synthetic_corpus, academic_corpus, output_file):
    """
    Merge synthetic and academic corpora.
    
    Args:
        synthetic_corpus (pd.DataFrame): Synthetic corpus
        academic_corpus (pd.DataFrame): Academic corpus
        output_file (str): Path to output file
        
    Returns:
        pd.DataFrame: Merged corpus
    """
    # Concatenate corpora
    merged_corpus = pd.concat([synthetic_corpus, academic_corpus])
    
    # Remove duplicates
    merged_corpus = merged_corpus.drop_duplicates()
    
    # Shuffle corpus
    merged_corpus = merged_corpus.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Save to file
    merged_corpus.to_csv(output_file, index=False)
    
    print(f"Created merged corpus with {len(merged_corpus)} samples")
    
    return merged_corpus

def train_transliteration_model(corpus, max_length=50):
    """
    Train the transliteration model.
    
    Args:
        corpus (pd.DataFrame): Parallel corpus
        max_length (int): Maximum sequence length
        
    Returns:
        BrahmiToDevanagariTransliterator: Trained transliterator
    """
    print("Training transliteration model...")
    
    # Extract texts
    brahmi_texts = corpus['brahmi'].tolist()
    devanagari_texts = corpus['devanagari'].tolist()
    
    # Create transliterator
    transliterator = BrahmiToDevanagariTransliterator(
        embedding_dim=128,  # Reduced from 256
        units=256,          # Reduced from 512
        batch_size=16       # Reduced from 64
    )
    
    # Preprocess data
    (encoder_input_train, decoder_input_train, decoder_target_train,
     encoder_input_test, decoder_input_test, decoder_target_test) = transliterator.preprocess_data(
        brahmi_texts, devanagari_texts, max_length=max_length
    )
    
    # Build model
    model = transliterator.build_model()
    
    # Create model directory
    model_dir = os.path.join('/home/ubuntu/brahmi_transliteration_project/models', 'transliteration')
    os.makedirs(model_dir, exist_ok=True)
    
    # Train model
    history = transliterator.train(
        encoder_input_train, decoder_input_train, decoder_target_train,
        encoder_input_test, decoder_input_test, decoder_target_test,
        epochs=20,  # Reduced from 50
        save_dir=model_dir
    )
    
    # Plot training history
    transliterator.plot_training_history(
        save_path=os.path.join(model_dir, 'training_history.png')
    )
    
    # Evaluate model
    metrics = transliterator.evaluate(
        encoder_input_test, decoder_input_test, decoder_target_test
    )
    
    print(f"Evaluation metrics: {metrics}")
    
    # Save model
    transliterator.save_model(model_dir)
    
    # Test transliteration
    test_brahmi_texts = [
        'ð‘€“ð‘€¸ð‘€¯ð‘€º',
        'ð‘€…ð‘€²ð‘„ð‘€“',
        'ð‘€¥ð‘€¼ð‘€¤ð‘†ð‘€¥'
    ]
    
    print("Testing transliteration:")
    for text in test_brahmi_texts:
        transliterated = transliterator.transliterate(text)
        print(f"Brahmi: {text} -> Devanagari: {transliterated}")
    
    return transliterator

def main():
    """
    Main function.
    """
    print("Starting Brahmi to Devanagari transliteration model training pipeline...")
    
    # Create data directory
    data_dir = os.path.join('/home/ubuntu/brahmi_transliteration_project/data', 'parallel_corpus')
    os.makedirs(data_dir, exist_ok=True)
    
    # Prepare synthetic corpus
    print("Preparing synthetic parallel corpus...")
    synthetic_corpus_path = os.path.join(data_dir, 'synthetic_corpus.csv')
    synthetic_corpus = prepare_synthetic_corpus(synthetic_corpus_path)
    
    # Prepare academic corpus
    print("Preparing academic corpus...")
    academic_corpus_path = os.path.join(data_dir, 'academic_corpus.csv')
    academic_corpus = prepare_academic_corpus(academic_corpus_path)
    
    # Merge corpora
    print("Merging corpora...")
    merged_corpus_path = os.path.join(data_dir, 'merged_corpus.csv')
    merged_corpus = merge_corpora(synthetic_corpus, academic_corpus, merged_corpus_path)
    
    # Train transliteration model
    transliterator = train_transliteration_model(merged_corpus)
    
    print("Transliteration model training pipeline completed successfully.")

if __name__ == "__main__":
    main()
